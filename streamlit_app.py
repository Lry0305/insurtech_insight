# é‡æ„ç¾åŒ–åçš„æœ€ç»ˆ streamlit_app.py å†…å®¹ï¼Œå¸¦åˆ†é¡µã€ç­›é€‰å™¨å’Œé”™è¯¯ä¿®å¤
final_beautified_code = '''
import streamlit as st
import pandas as pd
import json
import plotly.express as px
from matplotlib import rcParams
import matplotlib.pyplot as plt
from collections import Counter
import os
from wordcloud import WordCloud
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import re

rcParams['font.sans-serif'] = ['SimHei']
st.set_page_config(page_title="ä¿é™©ç§‘æŠ€æ™ºèƒ½åˆ†æå¹³å°", layout="wide")

# è¯»å–æ•°æ®
@st.cache_data
def load_data():
    return pd.read_csv("insurtech_results.csv")

df = load_data()

# è§£æ JSON å­—æ®µ
def extract_json_fields(df):
    sentiments, opinions, keywords_all, subjects = [], [], [], []
    for raw in df["åŸå§‹è¾“å‡º"]:
        try:
            content = json.loads(raw.replace("```json", "").replace("```", ""))
            sentiments.append(content.get("æƒ…ç»ª", "æœªæå–"))
            opinions.append(content.get("è§‚ç‚¹", ""))
            kws = content.get("å…³é”®è¯", [])
            ents = content.get("ä¸»ä½“", [])
            if isinstance(kws, list): keywords_all.extend(kws)
            if isinstance(ents, list): subjects.append(ents)
        except:
            sentiments.append("è§£æå¤±è´¥")
            opinions.append("")
            subjects.append([])
    return sentiments, opinions, keywords_all, subjects

df["æƒ…ç»ª"], df["è§‚ç‚¹"], all_keywords, df["ä¸»ä½“"] = extract_json_fields(df)

# ä»æ­£æ–‡ä¸­æå–æ—¶é—´ï¼ˆç®€å•è§„åˆ™ï¼‰
def extract_date(text):
    match = re.search(r"(\\d{4}-\\d{2}-\\d{2})", str(text))
    return match.group(1) if match else None

df["æ—¥æœŸ"] = df["æ­£æ–‡"].apply(extract_date)

# ==== ä¾§è¾¹æ ç­›é€‰å™¨ ====
with st.sidebar:
    st.header("ğŸ” æ•°æ®ç­›é€‰å™¨")
    sentiment_options = ["å…¨éƒ¨"] + sorted(df["æƒ…ç»ª"].dropna().unique().tolist())
    selected_sentiment = st.selectbox("æŒ‰æƒ…ç»ªç­›é€‰", sentiment_options)
    if selected_sentiment != "å…¨éƒ¨":
        df = df[df["æƒ…ç»ª"] == selected_sentiment]

# ==== é¡µé¢ç»“æ„åˆ’åˆ† ====
st.title("ğŸ“Š ä¿é™©ç§‘æŠ€è¡Œä¸šæ™ºèƒ½è§‚ç‚¹åˆ†æå¹³å°")
st.markdown("ğŸš€ å½“å‰å…±åŠ è½½æ–°é—»ï¼š**{}** æ¡".format(len(df)))
st.markdown("---")

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š æƒ…ç»ªä¸å…³é”®è¯", "ğŸ§  èšç±»åˆ†æ", "ğŸ¢ å…¬å¸ä¸æ—¶é—´", "ğŸ“„ æ•°æ®æ€»è§ˆ"])

with tab1:
    st.subheader("ğŸ“Š æƒ…ç»ªåˆ†å¸ƒ")
    sentiment_counts = df["æƒ…ç»ª"].value_counts().reset_index()
    sentiment_counts.columns = ["æƒ…ç»ª", "æ•°é‡"]
    fig_sentiment = px.pie(sentiment_counts, names="æƒ…ç»ª", values="æ•°é‡", title="æƒ…ç»ªå æ¯”")
    st.plotly_chart(fig_sentiment, use_container_width=True)

    st.subheader("ğŸ”¥ é«˜é¢‘å…³é”®è¯ Top20")
    kw_freq = Counter(all_keywords)
    top_kw = kw_freq.most_common(20)
    top_df = pd.DataFrame(top_kw, columns=["å…³é”®è¯", "å‡ºç°æ¬¡æ•°"])
    fig_bar = px.bar(top_df, x="å…³é”®è¯", y="å‡ºç°æ¬¡æ•°", text="å‡ºç°æ¬¡æ•°")
    st.plotly_chart(fig_bar, use_container_width=True)

    st.subheader("â˜ï¸ å…³é”®è¯è¯äº‘å›¾")
    def get_chinese_font():
        paths = [
            "C:/Windows/Fonts/simhei.ttf",
            "/System/Library/Fonts/STHeiti Medium.ttc",
            "/usr/share/fonts/truetype/arphic/ukai.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
        ]
        for path in paths:
            if os.path.exists(path): return path
        return None

    font_path = get_chinese_font()
    if font_path:
        wordcloud = WordCloud(font_path=font_path, background_color="white", width=800, height=400)
        wordcloud.generate_from_frequencies(kw_freq)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wordcloud, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)
    else:
        st.warning("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨ä¸­æ–‡å­—ä½“ï¼Œè¯äº‘å°†æ— æ³•æ˜¾ç¤ºä¸­æ–‡ã€‚")

with tab2:
    st.subheader("ğŸ§  è§‚ç‚¹èšç±»åˆ†æ")
    vectorizer = TfidfVectorizer(stop_words="english", max_features=100)
    X = vectorizer.fit_transform(df["è§‚ç‚¹"].fillna(""))
    k = 4
    model = KMeans(n_clusters=k, random_state=42)
    df["èšç±»æ ‡ç­¾"] = model.fit_predict(X)

    cluster_counts = df["èšç±»æ ‡ç­¾"].value_counts().sort_index()
    fig_cluster = px.bar(x=cluster_counts.index, y=cluster_counts.values,
                         labels={"x": "èšç±»æ ‡ç­¾", "y": "æ ·æœ¬æ•°"}, title="è§‚ç‚¹èšç±»åˆ†å¸ƒ")
    st.plotly_chart(fig_cluster, use_container_width=True)

    st.markdown("#### æ¯ç±»ä»£è¡¨æ€§è§‚ç‚¹ï¼ˆå‰3æ¡ï¼‰")
    for i in range(k):
        st.markdown(f"**ğŸŒ€ èšç±» {i}ï¼š**")
        sample = df[df["èšç±»æ ‡ç­¾"] == i]["è§‚ç‚¹"].dropna().head(3).tolist()
        for text in sample:
            st.markdown(f"- {text}")

with tab3:
    st.subheader("ğŸ“ˆ æƒ…ç»ªéšæ—¶é—´å˜åŒ–è¶‹åŠ¿")
    timeline_df = df.dropna(subset=["æ—¥æœŸ"])
    trend_data = timeline_df.groupby(["æ—¥æœŸ", "æƒ…ç»ª"]).size().reset_index(name="æ•°é‡")
    fig_time = px.line(trend_data, x="æ—¥æœŸ", y="æ•°é‡", color="æƒ…ç»ª", markers=True,
                       title="ä¸åŒæƒ…ç»ªæŠ¥é“éšæ—¶é—´è¶‹åŠ¿")
    st.plotly_chart(fig_time, use_container_width=True)

    st.subheader("ğŸ¢ ä¸»ä½“å…¬å¸æƒ…ç»ªåˆ†æ")
    def extract_entities(df):
        entities = []
        for raw in df["åŸå§‹è¾“å‡º"]:
            try:
                content = json.loads(raw.replace("```json", "").replace("```", ""))
                ents = content.get("ä¸»ä½“", [])
                if isinstance(ents, list):
                    for e in ents:
                        entities.append((e, content.get("æƒ…ç»ª", "æœªæå–")))
            except:
                continue
        return pd.DataFrame(entities, columns=["ä¸»ä½“", "æƒ…ç»ª"])

    ent_df = extract_entities(df)
    if not ent_df.empty:
        pivot = ent_df.groupby(["ä¸»ä½“", "æƒ…ç»ª"]).size().unstack(fill_value=0)
        top_entities = pivot.sum(axis=1).sort_values(ascending=False).head(6).index
        radar = pivot.loc[top_entities]
        fig_radar = px.line_polar(radar.reset_index(), r=radar.sum(axis=1), theta=radar.index,
                                  line_close=True, title="é«˜é¢‘å…¬å¸/æœºæ„æƒ…ç»ªå…³æ³¨å¼ºåº¦")
        st.plotly_chart(fig_radar, use_container_width=True)
    else:
        st.info("æœªæˆåŠŸæå–å…¬å¸ä¸»ä½“")

    st.subheader("ğŸ¤– è¡Œä¸šæ™ºèƒ½ä½“å»ºè®®")
    st.markdown("æç¤ºè¯ç¤ºä¾‹ï¼š")
    st.code("è¯·åˆ†æå½“å‰ä¿é™©ç§‘æŠ€è¡Œä¸šçš„å…³é”®è¯ï¼šæ™ºèƒ½æ ¸ä¿ã€æ•°å­—é£æ§ã€å®¢æˆ·ä½“éªŒ")

with tab4:
    st.subheader("ğŸ“„ åŸå§‹æ–°é—»æ•°æ®æ€»è§ˆ")
    st.dataframe(df[["æ ‡é¢˜", "æƒ…ç»ª", "é“¾æ¥"]], use_container_width=True)

    st.subheader("ğŸ“¥ ä¸€é”®å¯¼å‡ºæŠ¥å‘Š")
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ğŸ“¥ ä¸‹è½½ CSV", csv, file_name="insurtech_analysis.csv", mime="text/csv")
'''

# ä¿å­˜ä¸ºæœ€ç»ˆä¼˜åŒ–ç‰ˆæ–‡ä»¶
with open("D:/æ¯”èµ›/insurtech/streamlit_app_final_beautified.py", "w", encoding="utf-8") as f:
    f.write(final_beautified_code)
