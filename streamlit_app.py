import streamlit as st
import pandas as pd
import json
import plotly.express as px
from matplotlib import rcParams
import matplotlib.pyplot as plt
from collections import Counter
import os, re, requests
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans

rcParams['font.sans-serif'] = ['SimHei']
st.set_page_config(page_title="ä¿é™©ç§‘æŠ€æ™ºèƒ½åˆ†æå¹³å°", layout="wide")

# ========== 1. æ•°æ®åŠ è½½ä¸å¤„ç† ==========

@st.cache_data
def load_data():
    return pd.read_csv("insurtech_results.csv")

df = load_data()

def extract_json_fields(df):
    sentiments, opinions, keywords_all, subjects = [], [], [], []
    for raw in df["åŸå§‹è¾“å‡º"]:
        try:
            content = json.loads(raw.replace("```json", "").replace("```", ""))
            sentiments.append(content.get("æƒ…ç»ª", "æœªæå–"))
            opinions.append(content.get("è§‚ç‚¹", ""))
            kws = content.get("å…³é”®è¯", [])
            ents = content.get("ä¸»ä½“", [])
            if isinstance(kws, list): keywords_all.extend(kws)
            if isinstance(ents, list): subjects.append(ents)
        except:
            sentiments.append("è§£æå¤±è´¥")
            opinions.append("")
            subjects.append([])
    return sentiments, opinions, keywords_all, subjects

df["æƒ…ç»ª"], df["è§‚ç‚¹"], all_keywords, df["ä¸»ä½“"] = extract_json_fields(df)

# æ—¥æœŸæå–
def extract_date(text):
    match = re.search(r"(\d{4}-\d{2}-\d{2})", str(text))
    return match.group(1) if match else None

df["æ—¥æœŸ"] = df["æ­£æ–‡"].apply(extract_date)

# ========== 2. ä¾§è¾¹æ ç­›é€‰ ==========

with st.sidebar:
    st.header("ğŸ” æ•°æ®ç­›é€‰å™¨")
    sentiment_options = ["å…¨éƒ¨"] + sorted(df["æƒ…ç»ª"].dropna().unique().tolist())
    selected_sentiment = st.selectbox("æŒ‰æƒ…ç»ªç­›é€‰", sentiment_options)
    if selected_sentiment != "å…¨éƒ¨":
        df = df[df["æƒ…ç»ª"] == selected_sentiment]

# ========== 3. ä¸»ç•Œé¢æ ‡ç­¾ç»“æ„ ==========

st.title("ğŸ“Š ä¿é™©ç§‘æŠ€è¡Œä¸šæ™ºèƒ½è§‚ç‚¹åˆ†æå¹³å°")
st.markdown("ğŸš€ å½“å‰å…±åŠ è½½æ–°é—»ï¼š**{}** æ¡".format(len(df)))
st.markdown("---")

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“Š æƒ…ç»ªä¸å…³é”®è¯", "ğŸ§  èšç±»åˆ†æ", "ğŸ¢ å…¬å¸ä¸æ—¶é—´", "ğŸ¤– è¡Œä¸šæ™ºèƒ½ä½“", "ğŸ“„ æ•°æ®æ€»è§ˆ"
])

# ========== ğŸ“Š æƒ…ç»ªä¸å…³é”®è¯ ==========
with tab1:
    st.subheader("ğŸ“Š æƒ…ç»ªåˆ†å¸ƒ")
    sentiment_counts = df["æƒ…ç»ª"].value_counts().reset_index()
    sentiment_counts.columns = ["æƒ…ç»ª", "æ•°é‡"]
    fig_sentiment = px.pie(sentiment_counts, names="æƒ…ç»ª", values="æ•°é‡", title="æƒ…ç»ªå æ¯”")
    st.plotly_chart(fig_sentiment, use_container_width=True)

    st.subheader("ğŸ”¥ é«˜é¢‘å…³é”®è¯ Top20")
    kw_freq = Counter(all_keywords)
    top_kw = kw_freq.most_common(20)
    top_df = pd.DataFrame(top_kw, columns=["å…³é”®è¯", "å‡ºç°æ¬¡æ•°"])
    fig_bar = px.bar(top_df, x="å…³é”®è¯", y="å‡ºç°æ¬¡æ•°", text="å‡ºç°æ¬¡æ•°")
    st.plotly_chart(fig_bar, use_container_width=True)

    st.subheader("â˜ï¸ å…³é”®è¯è¯äº‘å›¾")
    def get_chinese_font():
        paths = [
            "C:/Windows/Fonts/simhei.ttf",
            "/System/Library/Fonts/STHeiti Medium.ttc",
            "/usr/share/fonts/truetype/arphic/ukai.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
        ]
        for path in paths:
            if os.path.exists(path): return path
        return None

    font_path = get_chinese_font()
    if font_path:
        wordcloud = WordCloud(font_path="font.ttf", background_color="white", width=800, height=400)
        wordcloud.generate_from_frequencies(kw_freq)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wordcloud, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)
    else:
        st.warning("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨ä¸­æ–‡å­—ä½“ï¼Œè¯äº‘å°†æ— æ³•æ˜¾ç¤ºä¸­æ–‡ã€‚")

# ========== ğŸ§  èšç±»åˆ†æ ==========
with tab2:
    st.subheader("ğŸ§  è§‚ç‚¹èšç±»åˆ†æ")
    vectorizer = TfidfVectorizer(stop_words="english", max_features=100)
    X = vectorizer.fit_transform(df["è§‚ç‚¹"].fillna(""))
    k = 4
    model = KMeans(n_clusters=k, random_state=42)
    df["èšç±»æ ‡ç­¾"] = model.fit_predict(X)

    cluster_counts = df["èšç±»æ ‡ç­¾"].value_counts().sort_index()
    fig_cluster = px.bar(x=cluster_counts.index, y=cluster_counts.values,
                         labels={"x": "èšç±»æ ‡ç­¾", "y": "æ ·æœ¬æ•°"}, title="è§‚ç‚¹èšç±»åˆ†å¸ƒ")
    st.plotly_chart(fig_cluster, use_container_width=True)

    st.markdown("#### æ¯ç±»ä»£è¡¨æ€§è§‚ç‚¹ï¼ˆå‰3æ¡ï¼‰")
    for i in range(k):
        st.markdown(f"**ğŸŒ€ èšç±» {i}ï¼š**")
        sample = df[df["èšç±»æ ‡ç­¾"] == i]["è§‚ç‚¹"].dropna().head(3).tolist()
        for text in sample:
            st.markdown(f"- {text}")

# ========== ğŸ¢ å…¬å¸ä¸æ—¶é—´ ==========
with tab3:
    st.subheader("ğŸ“ˆ æƒ…ç»ªéšæ—¶é—´å˜åŒ–è¶‹åŠ¿")
    timeline_df = df.dropna(subset=["æ—¥æœŸ"])
    trend_data = timeline_df.groupby(["æ—¥æœŸ", "æƒ…ç»ª"]).size().reset_index(name="æ•°é‡")
    fig_time = px.line(trend_data, x="æ—¥æœŸ", y="æ•°é‡", color="æƒ…ç»ª", markers=True,
                       title="ä¸åŒæƒ…ç»ªæŠ¥é“éšæ—¶é—´è¶‹åŠ¿")
    st.plotly_chart(fig_time, use_container_width=True)

    st.subheader("ğŸ¢ ä¸»ä½“å…¬å¸æƒ…ç»ªåˆ†æ")
    def extract_entities(df):
        entities = []
        for raw in df["åŸå§‹è¾“å‡º"]:
            try:
                content = json.loads(raw.replace("```json", "").replace("```", ""))
                ents = content.get("ä¸»ä½“", [])
                if isinstance(ents, list):
                    for e in ents:
                        entities.append((e, content.get("æƒ…ç»ª", "æœªæå–")))
            except:
                continue
        return pd.DataFrame(entities, columns=["ä¸»ä½“", "æƒ…ç»ª"])

    ent_df = extract_entities(df)
    if not ent_df.empty:
        pivot = ent_df.groupby(["ä¸»ä½“", "æƒ…ç»ª"]).size().unstack(fill_value=0)
        top_entities = pivot.sum(axis=1).sort_values(ascending=False).head(6).index
        radar = pivot.loc[top_entities]
        fig_radar = px.line_polar(radar.reset_index(), r=radar.sum(axis=1), theta=radar.index,
                                  line_close=True, title="é«˜é¢‘å…¬å¸/æœºæ„æƒ…ç»ªå…³æ³¨å¼ºåº¦")
        st.plotly_chart(fig_radar, use_container_width=True)
    else:
        st.info("æœªæˆåŠŸæå–å…¬å¸ä¸»ä½“")

# ========== ğŸ¤– æ™ºèƒ½ä½“åˆ†æ ==========
with tab4:
    st.subheader("ğŸ¤– è¡Œä¸šæ™ºèƒ½ä½“å¯¹è¯")

    DEEPSEEK_API_KEY = "sk-7b432ed6557d42939e8c52ae59a442c1"
    API_URL = "https://api.deepseek.com/v1/chat/completions"

    def call_deepseek(user_input):
        system_context = f"""
        ä½ æ˜¯ä¸€ä½ä¿é™©ç§‘æŠ€è¡Œä¸šçš„åˆ†æä¸“å®¶ï¼Œå…·å¤‡æ”¿ç­–ã€è¶‹åŠ¿ã€æŠ€æœ¯ã€æŠ•èµ„ç­‰æ–¹é¢çš„çŸ¥è¯†ã€‚
        å½“å‰çš„å…³é”®è¯åŒ…æ‹¬ï¼š{', '.join(top_df['å…³é”®è¯'].tolist()[:10])}ã€‚
        """
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_context},
                {"role": "user", "content": user_input}
            ],
            "temperature": 0.7
        }
        res = requests.post(API_URL, headers=headers, json=payload)
        return res.json()["choices"][0]["message"]["content"]

    if "chat" not in st.session_state:
        st.session_state.chat = []

    user_input = st.text_input("ğŸ” è¯·è¾“å…¥é—®é¢˜ï¼š", "")
    if user_input:
        with st.spinner("æ™ºèƒ½åˆ†æä¸­..."):
            reply = call_deepseek(user_input)
            st.session_state.chat.append(("ç”¨æˆ·", user_input))
            st.session_state.chat.append(("æ™ºèƒ½ä½“", reply))

    for role, msg in st.session_state.chat:
        st.chat_message(role).write(msg)

# ========== ğŸ“„ æ•°æ®æ€»è§ˆ ==========
with tab5:
    st.subheader("ğŸ“„ åŸå§‹æ–°é—»æ•°æ®æ€»è§ˆ")
    st.dataframe(df[["æ ‡é¢˜", "æƒ…ç»ª", "é“¾æ¥"]], use_container_width=True)

    st.subheader("ğŸ“¥ ä¸€é”®å¯¼å‡ºæŠ¥å‘Š")
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ğŸ“¥ ä¸‹è½½ CSV", csv, file_name="insurtech_analysis.csv", mime="text/csv")
